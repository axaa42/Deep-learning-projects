{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([' Mean of the integrated profile',\n",
       "       ' Standard deviation of the integrated profile',\n",
       "       ' Excess kurtosis of the integrated profile',\n",
       "       ' Skewness of the integrated profile', ' Mean of the DM-SNR curve',\n",
       "       ' Standard deviation of the DM-SNR curve',\n",
       "       ' Excess kurtosis of the DM-SNR curve', ' Skewness of the DM-SNR curve',\n",
       "       'target_class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"pulsar_stars.csv\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X=df.drop([\"target_class\"],axis=1)\n",
    "Y=df[\"target_class\"]\n",
    "scaler = StandardScaler()\n",
    "data_scaled=scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_scaled, Y, test_size=0.33,stratify=Y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopping=keras.callbacks.EarlyStopping(monitor = 'val_loss',\n",
    "                          \n",
    "                          patience = 3,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True) #This is to efficently stop training. eg estiamte val_loss,\n",
    "                                                       # patience is how much to wait for when loss is not improving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/14\n",
      "1080/1080 [==============================] - 1s 726us/step - loss: 0.1751 - accuracy: 0.9430 - val_loss: 0.0828 - val_accuracy: 0.9717\n",
      "Epoch 2/14\n",
      "1080/1080 [==============================] - 1s 620us/step - loss: 0.0777 - accuracy: 0.9774 - val_loss: 0.0813 - val_accuracy: 0.9733\n",
      "Epoch 3/14\n",
      "1080/1080 [==============================] - 1s 610us/step - loss: 0.0747 - accuracy: 0.9784 - val_loss: 0.0795 - val_accuracy: 0.9733\n",
      "Epoch 4/14\n",
      "1080/1080 [==============================] - 1s 607us/step - loss: 0.0726 - accuracy: 0.9785 - val_loss: 0.0791 - val_accuracy: 0.9717\n",
      "Epoch 5/14\n",
      "1080/1080 [==============================] - 1s 611us/step - loss: 0.0713 - accuracy: 0.9792 - val_loss: 0.0784 - val_accuracy: 0.9725\n",
      "Epoch 6/14\n",
      "1080/1080 [==============================] - 1s 600us/step - loss: 0.0702 - accuracy: 0.9794 - val_loss: 0.0778 - val_accuracy: 0.9742\n",
      "Epoch 7/14\n",
      "1080/1080 [==============================] - 1s 590us/step - loss: 0.0697 - accuracy: 0.9795 - val_loss: 0.0773 - val_accuracy: 0.9733\n",
      "Epoch 8/14\n",
      "1080/1080 [==============================] - 1s 581us/step - loss: 0.0688 - accuracy: 0.9805 - val_loss: 0.0769 - val_accuracy: 0.9742\n",
      "Epoch 9/14\n",
      "1080/1080 [==============================] - 1s 581us/step - loss: 0.0684 - accuracy: 0.9804 - val_loss: 0.0764 - val_accuracy: 0.9750\n",
      "Epoch 10/14\n",
      "1080/1080 [==============================] - 1s 567us/step - loss: 0.0678 - accuracy: 0.9803 - val_loss: 0.0776 - val_accuracy: 0.9725\n",
      "Epoch 11/14\n",
      "1080/1080 [==============================] - 1s 576us/step - loss: 0.0674 - accuracy: 0.9808 - val_loss: 0.0765 - val_accuracy: 0.9733\n",
      "Epoch 12/14\n",
      "1047/1080 [============================>.] - ETA: 0s - loss: 0.0667 - accuracy: 0.9802Restoring model weights from the end of the best epoch.\n",
      "1080/1080 [==============================] - 1s 592us/step - loss: 0.0666 - accuracy: 0.9802 - val_loss: 0.0773 - val_accuracy: 0.9742\n",
      "Epoch 00012: early stopping\n",
      "185/185 [==============================] - 0s 756us/step - loss: 0.0689 - accuracy: 0.9795\n",
      "Accuracy: 97.95\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X_train,y_train, epochs=14, batch_size=10, validation_split = 0.1,callbacks=[stopping])\n",
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X_test,y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning.\n",
    "- There are several ways to tune Hyperparameters of neural netowrk to get optimal values. \n",
    "\n",
    "- Here we will use grid search to find optimal values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "338/338 [==============================] - 0s 569us/step - loss: 0.2206 - accuracy: 0.9403\n",
      "Epoch 2/5\n",
      "338/338 [==============================] - 0s 578us/step - loss: 0.0872 - accuracy: 0.9753\n",
      "Epoch 3/5\n",
      "338/338 [==============================] - 0s 594us/step - loss: 0.0792 - accuracy: 0.9767\n",
      "Epoch 4/5\n",
      "338/338 [==============================] - 0s 587us/step - loss: 0.0759 - accuracy: 0.9773\n",
      "Epoch 5/5\n",
      "338/338 [==============================] - 0s 590us/step - loss: 0.0737 - accuracy: 0.9782\n",
      "Epoch 1/5\n",
      "338/338 [==============================] - 0s 556us/step - loss: 0.2303 - accuracy: 0.9434\n",
      "Epoch 2/5\n",
      "338/338 [==============================] - 0s 577us/step - loss: 0.0827 - accuracy: 0.9765\n",
      "Epoch 3/5\n",
      "338/338 [==============================] - 0s 575us/step - loss: 0.0775 - accuracy: 0.9765\n",
      "Epoch 4/5\n",
      "338/338 [==============================] - 0s 576us/step - loss: 0.0751 - accuracy: 0.9773\n",
      "Epoch 5/5\n",
      "338/338 [==============================] - 0s 582us/step - loss: 0.0733 - accuracy: 0.9775\n",
      "Epoch 1/5\n",
      "338/338 [==============================] - 0s 581us/step - loss: 0.3677 - accuracy: 0.8774\n",
      "Epoch 2/5\n",
      "338/338 [==============================] - 0s 575us/step - loss: 0.0974 - accuracy: 0.9736\n",
      "Epoch 3/5\n",
      "338/338 [==============================] - 0s 595us/step - loss: 0.0781 - accuracy: 0.9778\n",
      "Epoch 4/5\n",
      "338/338 [==============================] - 0s 576us/step - loss: 0.0737 - accuracy: 0.9784\n",
      "Epoch 5/5\n",
      "338/338 [==============================] - 0s 569us/step - loss: 0.0724 - accuracy: 0.9786\n",
      "Epoch 1/5\n",
      "338/338 [==============================] - 0s 579us/step - loss: 0.2215 - accuracy: 0.9463\n",
      "Epoch 2/5\n",
      "338/338 [==============================] - 0s 579us/step - loss: 0.0857 - accuracy: 0.9747\n",
      "Epoch 3/5\n",
      "338/338 [==============================] - 0s 566us/step - loss: 0.0796 - accuracy: 0.9757\n",
      "Epoch 4/5\n",
      "338/338 [==============================] - 0s 583us/step - loss: 0.0770 - accuracy: 0.9772\n",
      "Epoch 5/5\n",
      "338/338 [==============================] - 0s 583us/step - loss: 0.0752 - accuracy: 0.9774\n",
      "Epoch 1/5\n",
      "338/338 [==============================] - 0s 616us/step - loss: 0.2853 - accuracy: 0.9318\n",
      "Epoch 2/5\n",
      "338/338 [==============================] - 0s 637us/step - loss: 0.0855 - accuracy: 0.9754\n",
      "Epoch 3/5\n",
      "338/338 [==============================] - 0s 540us/step - loss: 0.0784 - accuracy: 0.9761\n",
      "Epoch 4/5\n",
      "338/338 [==============================] - 0s 555us/step - loss: 0.0757 - accuracy: 0.9765\n",
      "Epoch 5/5\n",
      "338/338 [==============================] - 0s 538us/step - loss: 0.0740 - accuracy: 0.9773\n",
      "Epoch 1/5\n",
      "338/338 [==============================] - 0s 627us/step - loss: 0.2291 - accuracy: 0.9559\n",
      "Epoch 2/5\n",
      "338/338 [==============================] - 0s 613us/step - loss: 0.0777 - accuracy: 0.9776\n",
      "Epoch 3/5\n",
      "338/338 [==============================] - 0s 550us/step - loss: 0.0741 - accuracy: 0.9780\n",
      "Epoch 4/5\n",
      "338/338 [==============================] - 0s 562us/step - loss: 0.0723 - accuracy: 0.9789\n",
      "Epoch 5/5\n",
      "338/338 [==============================] - 0s 567us/step - loss: 0.0709 - accuracy: 0.9789\n",
      "Epoch 1/5\n",
      "338/338 [==============================] - 0s 562us/step - loss: 0.2388 - accuracy: 0.9519\n",
      "Epoch 2/5\n",
      "338/338 [==============================] - 0s 573us/step - loss: 0.0879 - accuracy: 0.9750\n",
      "Epoch 3/5\n",
      "338/338 [==============================] - 0s 586us/step - loss: 0.0781 - accuracy: 0.9773\n",
      "Epoch 4/5\n",
      "338/338 [==============================] - 0s 569us/step - loss: 0.0746 - accuracy: 0.9775\n",
      "Epoch 5/5\n",
      "338/338 [==============================] - 0s 579us/step - loss: 0.0730 - accuracy: 0.9783\n",
      "Epoch 1/5\n",
      "338/338 [==============================] - 0s 582us/step - loss: 0.2444 - accuracy: 0.9424\n",
      "Epoch 2/5\n",
      "338/338 [==============================] - 0s 571us/step - loss: 0.0826 - accuracy: 0.9761\n",
      "Epoch 3/5\n",
      "338/338 [==============================] - 0s 553us/step - loss: 0.0789 - accuracy: 0.9766\n",
      "Epoch 4/5\n",
      "338/338 [==============================] - 0s 569us/step - loss: 0.0769 - accuracy: 0.9778\n",
      "Epoch 5/5\n",
      "338/338 [==============================] - 0s 558us/step - loss: 0.0756 - accuracy: 0.9780\n",
      "Epoch 1/5\n",
      "338/338 [==============================] - 0s 555us/step - loss: 0.1638 - accuracy: 0.9691\n",
      "Epoch 2/5\n",
      "338/338 [==============================] - 0s 578us/step - loss: 0.0806 - accuracy: 0.9769\n",
      "Epoch 3/5\n",
      "338/338 [==============================] - 0s 570us/step - loss: 0.0740 - accuracy: 0.9787\n",
      "Epoch 4/5\n",
      "338/338 [==============================] - 0s 594us/step - loss: 0.0710 - accuracy: 0.9790\n",
      "Epoch 5/5\n",
      "338/338 [==============================] - 0s 595us/step - loss: 0.0693 - accuracy: 0.9794\n",
      "Epoch 1/5\n",
      "338/338 [==============================] - 0s 604us/step - loss: 0.2352 - accuracy: 0.9439\n",
      "Epoch 2/5\n",
      "338/338 [==============================] - 0s 568us/step - loss: 0.0905 - accuracy: 0.9741\n",
      "Epoch 3/5\n",
      "338/338 [==============================] - 0s 573us/step - loss: 0.0819 - accuracy: 0.9766\n",
      "Epoch 4/5\n",
      "338/338 [==============================] - 0s 572us/step - loss: 0.0786 - accuracy: 0.9770\n",
      "Epoch 5/5\n",
      "338/338 [==============================] - 0s 573us/step - loss: 0.0763 - accuracy: 0.9772\n",
      "Epoch 1/5\n",
      "338/338 [==============================] - 0s 579us/step - loss: 0.2433 - accuracy: 0.9072\n",
      "Epoch 2/5\n",
      "338/338 [==============================] - 0s 578us/step - loss: 0.1250 - accuracy: 0.9592\n",
      "Epoch 3/5\n",
      "338/338 [==============================] - 0s 549us/step - loss: 0.1106 - accuracy: 0.9763\n",
      "Epoch 4/5\n",
      "338/338 [==============================] - 0s 546us/step - loss: 0.1018 - accuracy: 0.9773\n",
      "Epoch 5/5\n",
      "338/338 [==============================] - 0s 531us/step - loss: 0.0953 - accuracy: 0.9770\n",
      "Epoch 1/5\n",
      "338/338 [==============================] - 0s 551us/step - loss: 0.1999 - accuracy: 0.9538\n",
      "Epoch 2/5\n",
      "338/338 [==============================] - 0s 560us/step - loss: 0.0822 - accuracy: 0.9778\n",
      "Epoch 3/5\n",
      "338/338 [==============================] - 0s 573us/step - loss: 0.0765 - accuracy: 0.9788\n",
      "Epoch 4/5\n",
      "338/338 [==============================] - 0s 562us/step - loss: 0.0748 - accuracy: 0.9791\n",
      "Epoch 5/5\n",
      "338/338 [==============================] - 0s 571us/step - loss: 0.0736 - accuracy: 0.9794\n",
      "Epoch 1/5\n",
      "338/338 [==============================] - 0s 564us/step - loss: 0.2217 - accuracy: 0.9301\n",
      "Epoch 2/5\n",
      "338/338 [==============================] - 0s 562us/step - loss: 0.0813 - accuracy: 0.9769\n",
      "Epoch 3/5\n",
      "338/338 [==============================] - 0s 562us/step - loss: 0.0757 - accuracy: 0.9779\n",
      "Epoch 4/5\n",
      "338/338 [==============================] - 0s 547us/step - loss: 0.0738 - accuracy: 0.9779\n",
      "Epoch 5/5\n",
      "338/338 [==============================] - 0s 565us/step - loss: 0.0727 - accuracy: 0.9782\n",
      "Epoch 1/5\n",
      "338/338 [==============================] - 0s 597us/step - loss: 0.2632 - accuracy: 0.9347\n",
      "Epoch 2/5\n",
      "338/338 [==============================] - 0s 529us/step - loss: 0.0831 - accuracy: 0.9766\n",
      "Epoch 3/5\n",
      "338/338 [==============================] - 0s 542us/step - loss: 0.0788 - accuracy: 0.9774\n",
      "Epoch 4/5\n",
      "338/338 [==============================] - 0s 532us/step - loss: 0.0768 - accuracy: 0.9777\n",
      "Epoch 5/5\n",
      "338/338 [==============================] - 0s 532us/step - loss: 0.0756 - accuracy: 0.9781\n",
      "Epoch 1/5\n",
      "338/338 [==============================] - 0s 586us/step - loss: 0.2778 - accuracy: 0.9561\n",
      "Epoch 2/5\n",
      "338/338 [==============================] - 0s 551us/step - loss: 0.0883 - accuracy: 0.9752\n",
      "Epoch 3/5\n",
      "338/338 [==============================] - 0s 557us/step - loss: 0.0811 - accuracy: 0.9768\n",
      "Epoch 4/5\n",
      "338/338 [==============================] - 0s 552us/step - loss: 0.0781 - accuracy: 0.9765\n",
      "Epoch 5/5\n",
      "338/338 [==============================] - 0s 566us/step - loss: 0.0764 - accuracy: 0.9773\n",
      "Epoch 1/5\n",
      "338/338 [==============================] - 0s 556us/step - loss: 0.2021 - accuracy: 0.9610\n",
      "Epoch 2/5\n",
      "338/338 [==============================] - 0s 551us/step - loss: 0.0782 - accuracy: 0.9784\n",
      "Epoch 3/5\n",
      "338/338 [==============================] - 0s 550us/step - loss: 0.0755 - accuracy: 0.9789\n",
      "Epoch 4/5\n",
      "338/338 [==============================] - 0s 525us/step - loss: 0.0734 - accuracy: 0.9792\n",
      "Epoch 5/5\n",
      "338/338 [==============================] - 0s 526us/step - loss: 0.0725 - accuracy: 0.9796\n",
      "Epoch 1/5\n",
      "338/338 [==============================] - 0s 551us/step - loss: 0.3067 - accuracy: 0.9378\n",
      "Epoch 2/5\n",
      "338/338 [==============================] - 0s 549us/step - loss: 0.0874 - accuracy: 0.9752\n",
      "Epoch 3/5\n",
      "338/338 [==============================] - 0s 551us/step - loss: 0.0790 - accuracy: 0.9779\n",
      "Epoch 4/5\n",
      "338/338 [==============================] - 0s 525us/step - loss: 0.0760 - accuracy: 0.9779\n",
      "Epoch 5/5\n",
      "338/338 [==============================] - 0s 514us/step - loss: 0.0748 - accuracy: 0.9784\n",
      "Epoch 1/5\n",
      "338/338 [==============================] - 0s 552us/step - loss: 0.4282 - accuracy: 0.8952\n",
      "Epoch 2/5\n",
      "338/338 [==============================] - 0s 553us/step - loss: 0.0906 - accuracy: 0.9753\n",
      "Epoch 3/5\n",
      "338/338 [==============================] - 0s 570us/step - loss: 0.0794 - accuracy: 0.9768\n",
      "Epoch 4/5\n",
      "338/338 [==============================] - 0s 572us/step - loss: 0.0773 - accuracy: 0.9769\n",
      "Epoch 5/5\n",
      "338/338 [==============================] - 0s 567us/step - loss: 0.0758 - accuracy: 0.9780\n",
      "Epoch 1/5\n",
      "338/338 [==============================] - 0s 588us/step - loss: 0.2655 - accuracy: 0.9599\n",
      "Epoch 2/5\n",
      "338/338 [==============================] - 0s 559us/step - loss: 0.0895 - accuracy: 0.9753\n",
      "Epoch 3/5\n",
      "338/338 [==============================] - 0s 539us/step - loss: 0.0817 - accuracy: 0.9766\n",
      "Epoch 4/5\n",
      "338/338 [==============================] - 0s 549us/step - loss: 0.0777 - accuracy: 0.9777\n",
      "Epoch 5/5\n",
      "338/338 [==============================] - 0s 539us/step - loss: 0.0763 - accuracy: 0.9780\n",
      "Epoch 1/5\n",
      "338/338 [==============================] - 0s 564us/step - loss: 0.2905 - accuracy: 0.9207\n",
      "Epoch 2/5\n",
      "338/338 [==============================] - 0s 568us/step - loss: 0.0860 - accuracy: 0.9766\n",
      "Epoch 3/5\n",
      "338/338 [==============================] - 0s 559us/step - loss: 0.0802 - accuracy: 0.9769\n",
      "Epoch 4/5\n",
      "338/338 [==============================] - 0s 569us/step - loss: 0.0778 - accuracy: 0.9780\n",
      "Epoch 5/5\n",
      "338/338 [==============================] - 0s 571us/step - loss: 0.0759 - accuracy: 0.9789\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 0s 570us/step - loss: 0.1976 - accuracy: 0.9746\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 0s 565us/step - loss: 0.0762 - accuracy: 0.9781\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 0s 555us/step - loss: 0.0736 - accuracy: 0.9785\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 0s 567us/step - loss: 0.0721 - accuracy: 0.9791\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 0s 514us/step - loss: 0.0711 - accuracy: 0.9792\n",
      "{'batch_size': 32, 'epochs': 5, 'optimizer': 'adam'}\n",
      "0.9791506116207952\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "#The following is a function. we can input any hyperparemeter we want to test out eg dropout,neurons.optimzer, here we only \n",
    "# want to tune optimzer\n",
    "def build_classifier(optimizer):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(12, input_dim=8, activation='relu'))\n",
    "    model.add(keras.layers.Dense(8, activation='relu'))\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "# compile the keras model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "classifier = KerasClassifier(build_fn=build_classifier) # wrapper for function\n",
    "parameters = {'batch_size': [32],  # these are the hyperparameters we want to test out\n",
    "              'epochs': [5],\n",
    "              'optimizer': ['adam', 'rmsprop']}\n",
    "grid_search = GridSearchCV(estimator=classifier,\n",
    "                           param_grid=parameters,\n",
    "                           scoring='accuracy',\n",
    "                           cv=10) # ran for 10\n",
    "grid_search = grid_search.fit(X_train, y_train) # fit on grid search\n",
    "\n",
    "\n",
    "best_parameters = grid_search.best_params_ # best ones\n",
    "best_accuracy = grid_search.best_score_\n",
    "print(best_parameters)\n",
    "print(best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Downside of grid search is that it takes long time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
